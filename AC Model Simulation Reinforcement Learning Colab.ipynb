{"cells":[{"cell_type":"code","source":["!pip install yfinance"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_8XtFmwVkMo","executionInfo":{"status":"ok","timestamp":1659518026020,"user_tz":-540,"elapsed":4973,"user":{"displayName":"BonWoo Koo","userId":"10985288836138323738"}},"outputId":"ef082134-1f78-40bb-8d34-d59d87633a07"},"id":"m_8XtFmwVkMo","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement FinanceDataReader (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for FinanceDataReader\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting yfinance\n","  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n","Collecting requests>=2.26\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n","Installing collected packages: requests, yfinance\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","Successfully installed requests-2.28.1 yfinance-0.1.74\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","import syntheticChrissAlmgren as sca\n","from ddpg_agent import Agent\n","\n","from collections import deque\n","\n","# Create simulation environment\n","env = sca.MarketEnvironment()\n","\n","# Initialize Feed-forward DNNs for Actor and Critic models. \n","agent = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(), random_seed=0)\n","\n","# Set the liquidation time\n","lqt = 60\n","\n","# Set the number of trades\n","n_trades = 60\n","\n","# Set trader's risk aversion\n","tr = 1e-6\n","\n","# Set the number of episodes to run the simulation\n","episodes = 5000\n","\n","capture_hist = np.array([])\n","capture_deque = deque(maxlen=100)\n","\n","for episode in range(episodes): \n","    # Reset the enviroment\n","    cur_state = env.reset(seed = episode, liquid_time = lqt, num_trades = n_trades, lamb = tr)\n","\n","    # set the environment to make transactions\n","    env.start_transactions()\n","\n","    for i in range(n_trades + 1):\n","      \n","        # Predict the best action for the current state. \n","        action = agent.act(cur_state, add_noise = True)\n","        \n","        # Action is performed and new state, reward, info are received. \n","        new_state, reward, done, info = env.step(action)\n","        \n","        # current state, action, reward, new state are stored in the experience replay\n","        agent.step(cur_state, action, reward, new_state, done)\n","        \n","        # roll over new state\n","        cur_state = new_state\n","\n","        if info.done:\n","            capture_hist = np.append(capture_hist, info.totalCapture)\n","            capture_deque.append(info.totalCapture)\n","            break\n","    \n","    if episode == 0:\n","      print('Total Capture:', info.totalCapture)\n","    if (episode + 1) % 100 == 0: # print average total capture over last 100 episodes\n","        print('\\rEpisode [{}/{}]\\Total Capture: ${:,.2f}'.format(episode + 1, episodes, np.mean(capture_deque)))        \n","\n","print('\\nAverage Total Capture: ${:,.2f} \\n'.format(np.mean(capture_hist)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887},"id":"8PcEn1ScHOSy","executionInfo":{"status":"error","timestamp":1659520356267,"user_tz":-540,"elapsed":134876,"user":{"displayName":"BonWoo Koo","userId":"10985288836138323738"}},"outputId":"4cd58376-d7ff-43db-e453-2ceb0b780819"},"id":"8PcEn1ScHOSy","execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Total Capture: 48754265.32156216\n","Episode [100/5000]\\Total Capture: $47,723,144.50\n","Episode [200/5000]\\Total Capture: $47,437,743.47\n","Episode [300/5000]\\Total Capture: $47,437,500.00\n","Episode [400/5000]\\Total Capture: $47,437,500.00\n","Episode [500/5000]\\Total Capture: $47,437,500.00\n","Episode [600/5000]\\Total Capture: $47,437,500.00\n","Episode [700/5000]\\Total Capture: $47,437,500.00\n","Episode [800/5000]\\Total Capture: $47,437,500.00\n","Episode [900/5000]\\Total Capture: $47,437,500.00\n","Episode [1000/5000]\\Total Capture: $47,437,500.00\n","Episode [1100/5000]\\Total Capture: $47,437,500.00\n","Episode [1200/5000]\\Total Capture: $47,437,500.00\n","Episode [1300/5000]\\Total Capture: $47,437,500.00\n","Episode [1400/5000]\\Total Capture: $47,437,500.00\n","Episode [1500/5000]\\Total Capture: $47,437,500.00\n","Episode [1600/5000]\\Total Capture: $47,437,500.00\n","Episode [1700/5000]\\Total Capture: $47,437,500.00\n","Episode [1800/5000]\\Total Capture: $47,437,500.00\n","Episode [1900/5000]\\Total Capture: $47,437,500.00\n","Episode [2000/5000]\\Total Capture: $47,437,500.00\n","Episode [2100/5000]\\Total Capture: $47,725,069.91\n","Episode [2200/5000]\\Total Capture: $49,316,654.70\n","Episode [2300/5000]\\Total Capture: $49,325,551.15\n","Episode [2400/5000]\\Total Capture: $49,333,182.24\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-a33d95fcf362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# current state, action, reward, new state are stored in the experience replay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# roll over new state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# ---------------------------- update actor ---------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Compute actor loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mactions_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","torch.__version__\n","print(torch.cuda.device_count()) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"603vHYQo6lvE","executionInfo":{"status":"ok","timestamp":1659518034307,"user_tz":-540,"elapsed":3332,"user":{"displayName":"BonWoo Koo","userId":"10985288836138323738"}},"outputId":"68e0e1c2-e78d-4cd5-fb57-6e93182346ea"},"id":"603vHYQo6lvE","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]},{"cell_type":"code","source":["!pip3 install torch\n","!pip3 install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TYG3Y0SGb9eJ","executionInfo":{"status":"ok","timestamp":1659518045304,"user_tz":-540,"elapsed":8963,"user":{"displayName":"BonWoo Koo","userId":"10985288836138323738"}},"outputId":"602e1298-0f38-4d4e-bfe3-4d776afbfef6"},"id":"TYG3Y0SGb9eJ","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.0+cu113)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.28.1)\n","Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"]}]},{"cell_type":"code","source":["import torch\n","\n","dtype = torch.cuda.FloatTensor\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","x = torch.randn(N, D_in).type(dtype)\n","y = torch.randn(N, D_out).type(dtype)\n","w1 = torch.randn(D_in, H).type(dtype)\n","w2 = torch.randn(H, D_out).type(dtype)\n","learning_rate = 1e-6\n","\n","for t in range(500):\n","    h = x.mm(w1)\n","    h_relu = h.clamp(min=0)\n","    y_pred = h_relu.mm(w2)\n","    loss = (y_pred - y).pow(2).sum()\n","    print(t, loss)\n","\n","    grad_y_pred = 2.0 * (y_pred - y)\n","    grad_w2 = h_relu.t().mm(grad_y_pred)\n","    grad_h_relu = grad_y_pred.mm(w2.t())\n","    grad_h = grad_h_relu.clone()\n","    grad_h[h < 0] = 0\n","    grad_w1 = x.t().mm(grad_h)\n","\n","    w1 -= learning_rate * grad_w1\n","    w2 -= learning_rate * grad_w2"],"metadata":{"id":"gS5Lh208diNr"},"id":"gS5Lh208diNr","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":31,"id":"9729d49f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":978},"id":"9729d49f","executionInfo":{"status":"error","timestamp":1659521500438,"user_tz":-540,"elapsed":36594,"user":{"displayName":"BonWoo Koo","userId":"10985288836138323738"}},"outputId":"8208adf8-203a-48b6-9d47-fd518895ae4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[*********************100%***********************]  1 of 1 completed\n","[*********************100%***********************]  1 of 1 completed\n","True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Episode [100/5000]\\Total Capture: $128,215,977.97\n","Episode [200/5000]\\Total Capture: $128,134,607.00\n","Episode [300/5000]\\Total Capture: $128,134,607.00\n","Episode [400/5000]\\Total Capture: $128,134,607.00\n","Episode [500/5000]\\Total Capture: $128,134,607.00\n","Episode [600/5000]\\Total Capture: $128,134,607.00\n","Episode [700/5000]\\Total Capture: $128,134,607.00\n","Episode [800/5000]\\Total Capture: $128,134,607.00\n","Episode [900/5000]\\Total Capture: $128,134,607.00\n","Episode [1000/5000]\\Total Capture: $128,134,607.00\n","Episode [1100/5000]\\Total Capture: $128,134,607.00\n","Episode [1200/5000]\\Total Capture: $128,134,607.00\n","Episode [1300/5000]\\Total Capture: $128,134,607.00\n","Episode [1400/5000]\\Total Capture: $128,134,607.00\n","Episode [1500/5000]\\Total Capture: $128,134,607.00\n","Episode [1600/5000]\\Total Capture: $128,134,607.00\n","Episode [1700/5000]\\Total Capture: $128,134,607.00\n","Episode [1800/5000]\\Total Capture: $128,134,607.00\n","Episode [1900/5000]\\Total Capture: $128,134,607.00\n","Episode [2000/5000]\\Total Capture: $128,134,607.00\n","Episode [2100/5000]\\Total Capture: $128,134,607.00\n","Episode [2200/5000]\\Total Capture: $128,134,607.00\n","Episode [2300/5000]\\Total Capture: $128,134,607.00\n","Episode [2400/5000]\\Total Capture: $128,144,029.49\n","Episode [2500/5000]\\Total Capture: $128,144,029.49\n","Episode [2600/5000]\\Total Capture: $128,144,029.49\n","Episode [2700/5000]\\Total Capture: $128,144,029.49\n","Episode [2800/5000]\\Total Capture: $128,144,029.49\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-e688c9c3fab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0msimulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAC_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOTAL_SHARES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_TRADES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLIQUIDATION_TIME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mANNUAL_VOLAT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBID_ASK_SP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllambda_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m \u001b[0msimulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate_ac_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPISODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-31-e688c9c3fab0>\u001b[0m in \u001b[0;36msimulate_ac_model\u001b[0;34m(self, episodes)\u001b[0m\n\u001b[1;32m    205\u001b[0m                         \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrl_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                         \u001b[0mcur_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ddpg_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mexperiences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/ddpg_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, experiences, gamma)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","import copy\n","import syntheticChrissAlmgren2 as sca\n","import utils\n","import numpy as np\n","import yfinance as yf\n","import time\n","import sys\n","import matplotlib.pyplot as plt\n","from datetime import date, timedelta\n","from ddpg_agent import Agent\n","from collections import deque\n","\n","\n","\n","class AC_model():\n","    def __init__(self, TOTAL_SHARES, NUM_TRADES, LIQUIDATION_TIME, start_date, end_date, ticker, ANNUAL_VOLAT, BID_ASK_SP, llambda_list):\n","        \n","        self.TOTAL_SHARES = TOTAL_SHARES\n","        self.NUM_TRADES = NUM_TRADES\n","        self.LIQUIDATION_TIME = LIQUIDATION_TIME\n","        self.start_date = start_date\n","        self.end_date = end_date\n","        self.ticker = ticker\n","\n","        self.subtract_days = timedelta(NUM_TRADES)\n","        self.num_shares, self.last_num_shares = self.round_num_shares(self.TOTAL_SHARES, self.NUM_TRADES)\n","        self.data_origin =yf.download(ticker, start=start_date, end=end_date)\n","        self.TRAD_DAYS = len(self.data_origin['Open'])\n","        self.slidingwindow_num = self.TRAD_DAYS - NUM_TRADES + 1\n","        self.randomseed = 0                                \n","        self.BID_ASK_SP = BID_ASK_SP\n","        self.tau = 1\n","        self.DAILY_VOLAT = ANNUAL_VOLAT / np.sqrt(self.TRAD_DAYS)\n","        self.index_list = self.data_origin.index[:]\n","        self.llambda_list= llambda_list\n","        \n","        #DataFrame for Total Capture of \"High\" Price Execution and \"Low\" Price Execution\n","        self.df = yf.download(ticker, start = start_date-timedelta(self.TRAD_DAYS), end = end_date)\n","        self.df_trad = self.df.tail(self.TRAD_DAYS)\n","        self.total_cash_list, self.date_list = self.calculate_revenue(self.df_trad, 'High', self.slidingwindow_num, \n","                                                       self.NUM_TRADES, self.num_shares, self.last_num_shares)\n","        self.frame1 = pd.DataFrame({\"Date\": self.date_list, \"High\": self.total_cash_list})\n","\n","        self.total_cash_list2, self.date_list2 = self.calculate_revenue(self.df_trad, 'Low', self.slidingwindow_num, \n","                                                       self.NUM_TRADES, self.num_shares, self.last_num_shares)\n","        self.frame2 = pd.DataFrame({\"Date\": self.date_list2, \"Low\": self.total_cash_list2})\n","\n","    \n","    #TWAP method for determining number of shares to trade each day\n","    def round_num_shares(self, total_shares, num_trades):\n","        num_shares = total_shares // num_trades + 1\n","        last_num_shares = num_shares\n","        if type(total_shares / num_trades) != int:\n","            last_num_shares = total_shares - (num_shares*(num_trades-1))\n","\n","        return num_shares, last_num_shares\n","\n","    \n","    #Calculation of Total Capture of \"High\", \"Low\" Price Execution\n","    def calculate_revenue(self, df, category, slidingwindow_num, NUM_TRADES, num_shares, last_num_shares):\n","        total_cash_list = []\n","        date_list = []\n","        for window_num in range(slidingwindow_num):\n","            total_cash = 0\n","            for idx in range(NUM_TRADES):\n","                price = df[category][window_num:window_num+NUM_TRADES][idx]\n","                if idx == NUM_TRADES:\n","                    daily_cash = price * last_num_shares\n","                else:\n","                    daily_cash = price * num_shares\n","                total_cash += daily_cash\n","            total_cash_list.append(int(total_cash))\n","            date_list.append(df[category].index[window_num])\n","\n","        return total_cash_list, date_list\n","    \n","    \n","    #Simulation to identify if AC Model fits between \"High\" and \"Low\" Price Execution Band\n","    def simulate_ac_model(self, episodes):\n","        for risk in self.llambda_list:\n","            llambda = risk\n","            cnt = 0\n","            \n","            #Previous Stock Data with length of Liquidation Time is used for parameter calibration\n","            start = -abs(self.TRAD_DAYS+self.LIQUIDATION_TIME)\n","            end = -abs(self.TRAD_DAYS)\n","            ac_date_list =[]\n","            Actual_Revenue_List = []\n","            capture_list = []\n","            rl_capture_list =[]\n","\n","            for idx in range(self.slidingwindow_num):\n","                data = self.df.iloc[start:end]\n","                if end+NUM_TRADES != 0:\n","                    data_real_price = self.data_origin.iloc[end:end+self.NUM_TRADES]['Open'].to_numpy()\n","                else:\n","                    data_real_price = self.data_origin.iloc[end:]['Open'].to_numpy()\n","\n","                today = self.df.index[end]\n","                ac_date_list.append(today)\n","\n","                \n","                #Financial Parameters Calibration Using Past Stock Data\n","                average_daily_volume = np.mean(data['Volume'])\n","                average_daily_spread = np.mean(data['High'] - data['Low'])\n","                epsilon = average_daily_spread/2\n","                eta = average_daily_spread/(0.01*average_daily_volume)\n","                gamma = average_daily_spread/(0.1*average_daily_volume)\n","\n","                startingPrice = data.tail(1)['Close'][0]\n","                singleStepVariance = (self.DAILY_VOLAT  * startingPrice) ** 2\n","                \n","                #AC Environment Initialized with new financial parameters\n","                env = sca.MarketEnvironment()\n","                env.__init__(0, self.LIQUIDATION_TIME, self.NUM_TRADES,\n","                             llambda, startingPrice, epsilon, \n","                             eta, gamma, \n","                             self.TOTAL_SHARES, singleStepVariance)\n","\n","                # Get the trading list from the environment\n","                trl = env.get_trade_list()\n","\n","                # Since we are not selling fractional shares we round up the shares in the trading list\n","                trade_list = utils.round_trade_list(trl)\n","            \n","                # Implement the trading list in our similation environment            \n","                env.start_transactions()      \n","                price_hist = np.array([])\n","                                      \n","                for trade in trade_list:\n","                    # Normal AC Total Capture Calculation\n","                    # Convert the number of shares to sell in each trade into an action\n","                    action = trade / env.shares_remaining\n","\n","                    # Take a step in the environment my selling the number of shares in the current trade\n","                    _, _, _, info = env.step(action)\n","\n","                    # Get the impacted price from the environment\n","                    price_hist = np.append(price_hist, info.exec_price)\n","                    if info.done:\n","                        capture = info.totalCapture\n","\n","                    # If all shares have been sold, stop making transactions and get the implementation shortfall\n","                    if info.done:\n","                        #print('Implementation Shortfall: ${:,.2f} \\n'.format(info.implementation_shortfall))\n","                        break\n","\n","\n","                final_trade_list = np.trim_zeros(trade_list.astype(int))\n","                capture_list.append(int(capture))\n","                \n","                #print(\"AC Capture:\", capture)\n","\n","                if len(final_trade_list) != len(data_real_price):\n","                    length = len(final_trade_list)\n","                    modified_data_real_price = data_real_price[:length]\n","                else:\n","                    modified_data_real_price = data_real_price\n","\n","                Actual_Revenue_append = int(np.sum(final_trade_list*modified_data_real_price))\n","                Actual_Revenue_List.append(Actual_Revenue_append)\n","                \n","                \n","                #Create RL Environment\n","                rl_env = sca.MarketEnvironment()\n","                rl_env.__init__(0, self.LIQUIDATION_TIME, self.NUM_TRADES,\n","                             llambda, startingPrice, epsilon, \n","                             eta, gamma, \n","                             self.TOTAL_SHARES, singleStepVariance)\n","                \n","                rl_trl = rl_env.get_trade_list()\n","                rl_trade_list = utils.round_trade_list(trl)\n","                #print(rl_trade_list)\n","            \n","                agent = Agent(state_size=rl_env.observation_space_dimension(), action_size=rl_env.action_space_dimension(), \n","                              random_seed=0)\n","                \n","                print(next(agent.actor_local.parameters()).is_cuda)\n","                             \n","                rl_capture_hist = np.array([])\n","                rl_capture_deque = deque(maxlen=100)\n","                \n","                #Run Episodes for Reinforcement Learning\n","                for episode in range(episodes):\n","                    \n","                    #Reset RL Environment in every episode\n","                    rl_env.__init__(0, self.LIQUIDATION_TIME, self.NUM_TRADES,\n","                             llambda, startingPrice, epsilon, \n","                             eta, gamma, \n","                             self.TOTAL_SHARES, singleStepVariance)\n","                                    \n","                    rl_trl = rl_env.get_trade_list()\n","                    rl_trade_list = utils.round_trade_list(trl)\n","                    cur_state = np.array(list(rl_env.logReturns) + [rl_env.timeHorizon / rl_env.num_n, \\\n","                                                                           rl_env.shares_remaining / rl_env.total_shares])\n","                    \n","                    \n","                    rl_env.start_transactions()\n","        \n","                    for trade in rl_trade_list:\n","                        #RL Total Capture Learning\n","                        rl_action = agent.act(cur_state, add_noise = True)\n","                        \n","\n","                        new_state, rl_reward, done, rl_info = rl_env.step(rl_action)\n","\n","                        agent.step(cur_state, rl_action, rl_reward, new_state, done)\n","\n","                        cur_state = new_state\n","                        # if (episode + 1) % 100 == 0:\n","                        #     print(cur_state)\n","\n","                        if rl_info.done:\n","                            rl_capture_hist = np.append(rl_capture_hist, int(rl_info.totalCapture))\n","                            rl_capture_deque.append(int(rl_info.totalCapture))\n","                            break\n","                    \n","                    \n","                    if idx == 0:\n","                        if (episode + 1) % 100 == 0:\n","                            \n","                            print('\\rEpisode [{}/{}]\\Total Capture: ${:,.2f}'.format(episode + 1, episodes, np.mean(rl_capture_deque)))\n","                    \n","                    if episode+1 ==  episodes:\n","                        #print(rl_trade_list)\n","                        print('\\rEpisode [{}/{}]\\Total Capture: ${:,.2f}'.format(episode + 1, episodes, np.mean(rl_capture_deque)))\n","\n","                        \n","                #Append Extracted Total Capture of a specified liquidation start date        \n","                rl_capture_list = np.append(rl_capture_list, np.mean(rl_capture_deque))\n","                \n","             \n","                start += 1\n","                end += 1\n","\n","                \n","                \n","#                 #GBM Price Chart with High, Low price band\n","#                 if llambda == 1e-10 and idx == 0:\n","#                     price_list_num = len(price_hist)\n","                    \n","#                     GBM_price_frame = pd.DataFrame({\"Date\":self.index_list[:price_list_num], \"Price\": price_hist})\n","#                     GBM_price_frame.set_index(\"Date\", inplace = True)\n","#                     REAL_LOW_price_frame = self.data_origin['Low'].head(price_list_num)\n","                    \n","#                     REAL_HIGH_price_frame = self.data_origin['High'].head(price_list_num)\n","#                     realFrame = pd.merge(REAL_LOW_price_frame, REAL_HIGH_price_frame,left_index=True, right_index=True)\n","#                     finalFrame = pd.merge(realFrame,GBM_price_frame, left_index=True, right_index=True)\n","#                     finalFrame.plot()\n","                \n","    \n","#                 #Stopping on a first date to check the ability of RL method compared to normal AC optimization\n","                if idx == 0:\n","                    break\n","\n","\n","            #Plot Total Capture Comparison Graph of slidingwindow    \n","            rlframe = pd.DataFrame({\"Date\": ac_date_list, \"RL_GBM\": rl_capture_list})\n","            ACframe = pd.DataFrame({\"Date\": ac_date_list, \"AC_Model\":capture_list})\n","            ARframe = pd.DataFrame({\"Date\": ac_date_list, \"Actual_Revenue\": Actual_Revenue_List})\n","            newframe = pd.merge(self.frame1, self.frame2, how='inner', on='Date').merge(ACframe, on = 'Date').merge(rlframe, on=\"Date\")\n","            newframe.set_index(\"Date\", inplace=True)\n","\n","            plt.rcParams['figure.figsize'] = [17.0, 7.0]\n","            titleName = \"risk =\" + str(llambda)\n","            newframe.plot(title = titleName)\n","\n","\n","            \n","            \n","\n","TOTAL_SHARES = 1000000\n","NUM_TRADES = 6\n","LIQUIDATION_TIME = 6\n","start_date = date(2021,1,1)\n","end_date = '2021-02-01'\n","ticker = 'AAPL'\n","ANNUAL_VOLAT = 0.12                                \n","BID_ASK_SP = 1 / 8                                                                 \n","llambda_list= [1e-06]\n","plt.rcParams['figure.figsize'] = [17.0, 7.0]\n","EPISODES = 5000\n","\n","simulation = AC_model(TOTAL_SHARES, NUM_TRADES, LIQUIDATION_TIME, start_date, end_date, ticker, ANNUAL_VOLAT, BID_ASK_SP, llambda_list)\n","simulation.simulate_ac_model(EPISODES)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"AC Model Simulation Reinforcement Learning Colab.ipynb","provenance":[],"collapsed_sections":[]},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}